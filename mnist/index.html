<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<!-- <script>
  for (const iterator of document.getElementsByClassName('page-link')) {
      if (iterator.innerHTML === 'Search'){ iterator.classList.add('search-button'); iterator.title = 'Search';}
      if (iterator.innerHTML === 'Tags'){ iterator.classList.add('tags-button'); iterator.title = 'Tags';}
      if (iterator.innerHTML === 'Side Projects'){ iterator.classList.add('side-project-button'); iterator.title = 'Side Projects';}
  }
</script> --><html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript" src="/assets/accordian.js"></script>

<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Digit Recognition</h1>

    <p class="page-description">MNIST: Kaggle Getting Started</p>
<p class="post-meta post-meta-title"><time class="dt-published post-meta-created-date" datetime="2020-03-30T00:00:00-05:00" itemprop="datePublished">
        Written: Mar 30, 2020
      </time>~<time class="dt-modified post-meta-last-modified-date" datetime="2020-03-30T15:42:15-05:00" itemprop="dateModified">
          Updated: Mar 30, 2020
        </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>    <style>
        .post-tool-bar{
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0px 10px 0px;
            /* border: 1px solid #e8e8e8; */
            border-width: 0px 0px 1px 0px;
        }
        .left-section , .right-section{
            display: flex;
            gap: 8px;
        }

    </style>
    
    <div class="post-tool-bar">
<!-- <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet">
<script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
<script>
        AOS.init();
</script> -->

<div class="tag-list">
    
    <a class="tag fa fa-hashtag deep-learning" href="/categories/#deep-learning">deep-learning</a>
    
</div>
<div class="right-section">
<a id="translate-btn" href="https://www.translatetheweb.com/?ref=TAns&from=&to=hi&a=https%3A%2F%2Fwww.ankushchoubey.com%2F">
    <img src="/images/icons/translate.svg" alt="Translate" style="width:35px">
</a>


<script>
    a = document.getElementById('translate-btn');
    a.setAttribute("href", "https://www.translatetheweb.com/?ref=TAns&from=&to=hi&a=" + window.location.href);
</script><a id="speech-btn">
    <img src="/images/icons/ear.svg" alt="listen" style="width:35px; cursor: pointer;">
</a>

<script>
    speakPost = () => {
        var msg = new SpeechSynthesisUtterance();
        const title = document.querySelector("h1.post-title.p-name").innerText;
        const post = document.querySelector("div.post-content.e-content").innerText
        msg.text = title + '.' + post;
        window.speechSynthesis.speak(msg);
    }
    if ('speechSynthesis' in window) {
        document.getElementById("speech-btn").addEventListener("click", speakPost);
    } else {
        document.getElementById('speech-btn').style.display = 'none';
    }
</script>

<!-- https://www.alebalweb-blog.com/85-text-to-speech-player-with-buttons-play-pause-stop-and-voice-choice.html -->
</div>
      
          
    </div>
    
</header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h3"><a href="#how-to-read-this">How to read this?</a></li>
<li class="toc-entry toc-h3">
<a href="#commit-version-2-getting-input-and-generating-submission-file">Commit Version 2: Getting Input and Generating Submission File</a>
<ul>
<li class="toc-entry toc-h4"><a href="#read-the-data">Read the data</a></li>
<li class="toc-entry toc-h4"><a href="#trainingtesting">Training/testing</a></li>
<li class="toc-entry toc-h4"><a href="#dataset">Dataset</a></li>
<li class="toc-entry toc-h4"><a href="#creating-dataloader">Creating DataLoader</a></li>
<li class="toc-entry toc-h4"><a href="#checking-if-dataloader-returns-the-right-output">Checking if DataLoader returns the right output</a></li>
<li class="toc-entry toc-h4"><a href="#creating-a-vanilla-neural-network">Creating a vanilla Neural Network</a></li>
<li class="toc-entry toc-h4"><a href="#preparing-the-training-loop">Preparing the training loop</a></li>
<li class="toc-entry toc-h4"><a href="#creating-the-training-loop">Creating the training loop</a></li>
<li class="toc-entry toc-h4"><a href="#generating-output">Generating output</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#commit-version-3-improvements">Commit Version 3: Improvements</a>
<ul>
<li class="toc-entry toc-h4"><a href="#proper-accuracy">Proper Accuracy</a></li>
<li class="toc-entry toc-h4"><a href="#graph">Graph</a></li>
<li class="toc-entry toc-h4"><a href="#data-normalization">Data Normalization</a></li>
</ul>
</li>
<li class="toc-entry toc-h3">
<a href="#commit-6-convnet-and-gpu">Commit 6: ConvNet, and GPU</a>
<ul>
<li class="toc-entry toc-h4"><a href="#convnet">ConvNet</a></li>
<li class="toc-entry toc-h4"><a href="#gpu">GPU</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#commit-7-improvement">Commit 7: Improvement</a></li>
</ul>
<hr>
<h3 id="how-to-read-this">
<a class="anchor" href="#how-to-read-this" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to read this?</h3>
<ol>
  <li>
    <p>Skim through the <a href="https://medium.com/p/c06251780b">Pre-requisites</a></p>
  </li>
  <li>
    <p>Open each commit notebook then read the explanations.</p>
  </li>
  <li>
    <p>Just run each notebook top to bottom.</p>
  </li>
  <li>
    <p>Try to understand each line.</p>
  </li>
  <li>
    <p>If you find yourself stuck at statements, explore the variable involved.</p>
  </li>
  <li>
    <p>Still, <strong>stuck</strong>?? <strong>highlight the explanation and comment</strong>. I will get back to your query.</p>
  </li>
</ol>

<hr>

<h3 id="commit-version-2-getting-input-and-generating-submission-file">
<a class="anchor" href="#commit-version-2-getting-input-and-generating-submission-file" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://www.kaggle.com/ankschoubey/20200324-pytorch-mnist?scriptVersionId=30660257">Commit Version 2</a>: Getting Input and Generating Submission File</h3>

<ul>
  <li>
    <p><em>Day 1</em></p>
  </li>
  <li>
    <p>Score — 0.43</p>
  </li>
  <li>
    <p>Time invested — about an hour</p>
  </li>
</ul>

<p>My goal for any first commit is always to get input, pass it through a NN and generate a submittable output.</p>

<h4 id="read-the-data">
<a class="anchor" href="#read-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Read the data</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/digit-recognizer/train.csv'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="trainingtesting">
<a class="anchor" href="#trainingtesting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training/testing</h4>

<p>I needed a way to separate features and labels.</p>

<p>So the easiest way was to not select a column named ‘label’.</p>

<p><em>test_df</em> does not contain a label column</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">train_df</span><span class="p">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s">'label'</span><span class="p">]</span>
<span class="nb">type</span><span class="p">(</span><span class="n">test_df</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'label'</span><span class="p">))</span> <span class="o">==</span> <span class="bp">None</span>
<span class="c1">#false
</span></code></pre></div></div>

<h4 id="dataset">
<a class="anchor" href="#dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset</h4>

<p>Returns features and labels if ‘train=True’. else it returns just features</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MnistDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="c1">#convert df to self.X and self.y using above
</span>
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">train</span><span class="p">:</span> <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre></div></div>

<p>Observation: Even if I don’t explicitly mention Tensor, NumPy is converted to tensor.</p>

<h4 id="creating-dataloader">
<a class="anchor" href="#creating-dataloader" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating DataLoader</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bs</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">ds</span> <span class="o">=</span> <span class="n">MnistDataset</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
<span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="checking-if-dataloader-returns-the-right-output">
<a class="anchor" href="#checking-if-dataloader-returns-the-right-output" aria-hidden="true"><span class="octicon octicon-link"></span></a>Checking if DataLoader returns the right output</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">))</span>
<span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<h4 id="creating-a-vanilla-neural-network">
<a class="anchor" href="#creating-a-vanilla-neural-network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a vanilla Neural Network</h4>

<p>I created a dumb NN just so that I can pass data through it and get output in the desired shape.</p>

<p>The details don’t matter much. This will be replaced by a CNN later.</p>

<h4 id="preparing-the-training-loop">
<a class="anchor" href="#preparing-the-training-loop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing the training loop</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="n">o</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>
</code></pre></div></div>

<h4 id="creating-the-training-loop">
<a class="anchor" href="#creating-the-training-loop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating the training loop</h4>

<p>Here are the 4 steps to create a basic training loop</p>

<ol>
  <li><strong>Loop epoch number of times</strong></li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="p">...</span>
</code></pre></div></div>

<ol>
  <li>Inside the epoch loop, <strong>loop through data loader</strong> (dl)</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
    <span class="p">...</span>
</code></pre></div></div>

<ol>
  <li>Inside the data loader loop,</li>
</ol>

<ul>
  <li>
    <p><strong>zero</strong> <strong>grad optimizer</strong> <strong>before passing pushing data</strong> into NN.</p>
  </li>
  <li>
    <p>Take an <strong>optimizer step after pushing data</strong> through NN.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">o</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="p">...</span>
<span class="n">o</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<ol>
  <li>Between optimizer zero_grad and optimizer step, <strong>pass data through the NN, compute loss and gradients.</strong>
</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="nb">float</span><span class="p">())</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span> <span class="n">labels</span><span class="p">.</span><span class="nb">long</span><span class="p">())</span>
<span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="generating-output">
<a class="anchor" href="#generating-output" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generating output</h4>

<p>A similar step as above has been taken to generate test_dl and the testing loop.</p>

<p>The only difference,</p>

<ul>
  <li>
    <p>test_dl has ‘train=true’. Dataset will only return features and not labels.</p>
  </li>
  <li>
    <p>code to not calculate gradients since we are not training.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="p">...</span>
</code></pre></div></div>

<ul>
  <li>
    <p>The output is in the form of numbers from 0…9.</p>
  </li>
  <li>
    <p>Our output is a column <strong><em>(dim=1)</em></strong> array of length 10 with probability.</p>
  </li>
  <li>
    <p>The maximum of this array is our output.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">out</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We store these outputs in an <strong>outputs</strong> python list.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_df</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample_df</span><span class="p">.</span><span class="n">shape</span>
<span class="c1"># Out[17]: ((28000, 784), (28000, 2))
</span></code></pre></div></div>

<ul>
  <li>
    <p>I realized that sample submission and output df have the same length.</p>
  </li>
  <li>
    <p>I just need to add ‘Label’ column to the submission data frame and save it in CSV form.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_df</span><span class="p">[</span><span class="s">'Label'</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
<span class="n">sample_df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>index=False</strong> removed the default pandas index when saving</p>

<h3 id="commit-version-3-improvements">
<a class="anchor" href="#commit-version-3-improvements" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://www.kaggle.com/ankschoubey/20200324-pytorch-mnist?scriptVersionId=30753580">Commit Version 3</a>: Improvements</h3>

<p><em>Changes</em>: Proper Accuracy, Graph, and Data Normalization</p>

<ul>
  <li>
    <p><em>Day 4</em></p>
  </li>
  <li>
    <p>Score — 0.96</p>
  </li>
  <li>
    <p>Time invested — about an hour</p>
  </li>
</ul>

<h4 id="proper-accuracy">
<a class="anchor" href="#proper-accuracy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Proper Accuracy</h4>

<p>Accuracy should always be calculated on the validation set.</p>

<p><strong><em>Creating a separate validation set</em></strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">val_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span><span class="p">)</span> <span class="c1"># 0.01 percent of data
</span><span class="n">train_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span> <span class="err">—</span> <span class="n">val_len</span> <span class="c1"># all other are in training
</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>

<span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="p">[</span><span class="n">train_len</span><span class="p">,</span> <span class="n">val_len</span><span class="p">])</span>
</code></pre></div></div>

<p>Likewise, 2 data loaders are created.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bs</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
<span class="n">val_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
</code></pre></div></div>

<p><strong><em>Changes in the training loop</em></strong></p>

<p>A separate list called accuracies in created to store the accuracy of an epoch.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_dl</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">.</span><span class="nb">float</span><span class="p">())</span>
            <span class="n">accuracy</span><span class="o">+=</span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
        <span class="n">accuracies</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="graph">
<a class="anchor" href="#graph" aria-hidden="true"><span class="octicon octicon-link"></span></a>Graph</h4>

<p>Since the accuracy of each epoch was stored in a separate accuracies list, creating a graph was easy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">accuracies</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="data-normalization">
<a class="anchor" href="#data-normalization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Normalization</h4>

<p>After plotting the graph, I realized accuracy was 43% which is the same as the score of commit 2.</p>

<p>The easiest thing to do was to normalize the data.</p>

<p>Since MNIST images are in the range of 1…250 the easiest thing to do was to divide by 250 which would result in a range of 0…1.</p>

<p>Ideally, the range should be around 0 so an even better approach would be</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">/</span><span class="mi">250</span><span class="err">–</span><span class="mf">0.5</span>
</code></pre></div></div>

<p>this would result in a range between -0.5…+0.5.</p>

<p>Later we would use <code class="language-plaintext highlighter-rouge">torchvision.transforms.Normalize</code>(<em>mean</em>, <em>std</em>, <em>inplace=False</em>) which generates unique normalization value for each dataset</p>

<h3 id="commit-6-convnet-and-gpu">
<a class="anchor" href="#commit-6-convnet-and-gpu" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://www.kaggle.com/ankschoubey/20200326-pytorch-mnist?scriptVersionId=30896320">Commit 6</a>: ConvNet, and GPU</h3>

<ul>
  <li>
    <p>Day 6</p>
  </li>
  <li>
    <p>Score — 0.97</p>
  </li>
  <li>
    <p>Time invested — about 2 hours (lots of googling and reading docs) + 1 hours fixes bugs</p>
  </li>
</ul>

<h4 id="convnet">
<a class="anchor" href="#convnet" aria-hidden="true"><span class="octicon octicon-link"></span></a>ConvNet</h4>

<p>Convolutional Neural Networks are ideal images.</p>

<p><strong><em>ResNet</em></strong></p>

<p>ResNet 34 is my goto ConvNet but since MNIST is so easy, I went with ResNet 18.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>
<span class="n">resnet18</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">resnet18</span><span class="p">.</span><span class="n">fc</span> <span class="c1">#print fully connected network
</span></code></pre></div></div>

<p>ResNet is designed to output 1000 classes. But our output is from 0…9 aka 10 classes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lin_in</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">in_features</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="n">resnet18</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">lin_in</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong><em>Convert Grayscale to RGB image</em></strong></p>

<p>ResNet expects RGB images. MNIST is grayscale.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="err">`</span>
</code></pre></div></div>

<p>This <a href="https://discuss.pytorch.org/t/grayscale-to-rgb-transform/18315/7">grayscale to the RGB</a> line is added to our Dataset class.</p>

<p><strong><em>Normalization</em></strong></p>

<p>When using an existing model, we need to use the same normalization values as that model. The <a href="#https://pytorch.org/docs/stable/torchvision/models.html">docs mention the normalization value</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span>  <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>
<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</code></pre></div></div>

<p>The <strong>init</strong> and <strong>getitem</strong> dataset class have been modified to use this transformation.</p>

<p>Modifications have also been made to test_ds.</p>

<h4 id="gpu">
<a class="anchor" href="#gpu" aria-hidden="true"><span class="octicon octicon-link"></span></a>GPU</h4>

<p>One I started the training loop, I realized it suddenly became too slow.</p>

<p>GPU is needed!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda:0'</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
</code></pre></div></div>

<p>If the GPU is on, the device will be <em>cuda</em>.</p>

<p>The neural network and the data in training, validation and texting loop have been changed to run on GPU.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>And since we are on GPU we can increase our batch size from 64 to much higher.</p>

<p>I experimented with a few sizes from 320…640 and kept an eye on GPU utilization and settled for 512.</p>

<p><img src="/images/2020-03-30-digit-recognition/1.png" alt="CPU and GPU Utilization. Also, see the number of tabs open."></p>

<p>I did the same for <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/2">num_worker</a> which specifies the number of threads to load a batch. This is CPU stuff.</p>

<p>Along with monitoring GPU and CPU usage, I modified training_loop to show the <a href="https://stackoverflow.com/a/36423341">amount of time taken to complete each epoch</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bs</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
<span class="n">val_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>
</code></pre></div></div>

<p>This resulted in 7 seconds per epoch.</p>

<p>For testing, the batch_size can be much higher since we don’t have to back prop.</p>

<h3 id="commit-7-improvement">
<a class="anchor" href="#commit-7-improvement" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://www.kaggle.com/ankschoubey/20200326-pytorch-mnist/output?scriptVersionId=31120757">Commit 7</a>: Improvement</h3>

<ul>
  <li>
    <p>Day 8</p>
  </li>
  <li>
    <p>Score — 0.97</p>
  </li>
  <li>
    <p>Time invested — about 30 minutes</p>
  </li>
</ul>

<p>I learned that you don’t need <a href="https://discuss.pytorch.org/t/vgg-output-layer-no-softmax/9273">nn.Softmax if you are using nn.CrossEntropyLoss</a>.</p>

<p>nn.CrossEntropyLoss has nn.Softmax built-in and the results of softmax are not used during back-prop. So it can be safely removed.</p>

<p>Now FC is this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lin_in</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">in_features</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="n">resnet18</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">lin_in</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>
<hr>

<p>Index: <a href="/deep%20learning/kaggle/2020/03/30/series-kaggle-getting-started.html">Series - Kaggle Getting Started</a></p>

<p>Next Post: []</p>

  </div>
  <!-- https://david.elbe.me/jekyll/2015/06/20/how-to-link-to-next-and-previous-post-with-jekyll.html -->

<div class="PageNavigation">
    
      <a class="prev" href="/kaggle_download_folder/">« Kaggle CLI QA: How to download a particular folder</a>
    
    
      <a class="next" href="/kaggle_getting_started/">Series  Kaggle Getting Started »</a>
    
  </div>

<style>
    .PageNavigation {
  font-size: 14px;
  display: block;
  width: auto;
  overflow: hidden;
}

.PageNavigation a {
  display: block;
  width: 50%;
  float: left;
  margin: 1em 0;
}

.PageNavigation .next {
  text-align: right;
}
</style>
<!-- from https://github.com/utterance/utterances -->
<!-- <script src="https://utteranc.es/client.js"
        repo="ankschoubey/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script> -->

  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://www.ankushchoubey.com/mnist/';
      this.page.identifier = 'https://www.ankushchoubey.com/mnist/';
    };
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://ankushchoubey.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
<a class="u-url" href="/mnist/" hidden></a>
</article>
</head></html>
